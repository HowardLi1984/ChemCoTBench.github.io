<!DOCTYPE html>
<html lang="en">
  <head>
    <title>ChemCoTBench</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
    <meta charset="utf-8">
    <meta name="description"
          content="A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI">
    <meta name="keywords" content="MMMU, LMM, LMM Evaluation, Vision Language Model, Large Language Model, Large Multimodal Model, artificial intelligence, AI, AGI, artificial general intelligence">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI</title>

    <link rel="icon" href="./static/images/mmmu_icon2.png">

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <script src="https://kit.fontawesome.com/fff5b27ec1.js" crossorigin="anonymous"></script>
    <!-- <script src="https://kit.fontawesome.com/eaf1856e6f.js" crossorigin="anonymous"></script> -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>
  <body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link">
              More Research
            </a>
            <div class="navbar-dropdown">
              <a class="navbar-item" href="https://huggingface.co/datasets/MMMU/MMMU_Pro">
                <b>MMMU-Pro</b> <span style="font-size:18px; display: inline; margin-left: 5px;">ðŸ”¥</span>
              </a>
              <a class="navbar-item" href="https://tiger-ai-lab.github.io/MAmmoTH/">
                MAmmoTH
              </a>
              <a class="navbar-item" href="https://osu-nlp-group.github.io/TableLlama/">
                TableLlama
              </a>
              <a class="navbar-item" href="https://osu-nlp-group.github.io/MagicBrush/">
                MagicBrush
              </a>
              <a class="navbar-item" href="https://osu-nlp-group.github.io/Mind2Web/">
                Mind2Web
              </a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title is-bold">
                <img src="static/images/mmmu_icon2.png" style="width:1em;vertical-align: middle" alt="Logo"/>
                <span class="mmmu" style="vertical-align: middle">ChemCoTBench</span>
              </h1>
              <h2 class="subtitle is-3 publication-subtitle">
                Beyond Chemical QA, Evaluating LLM's Chemical Reasoning with Modular Chemical Operations
              </h2>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://howardli1984.github.io/" style="text-decoration: none; color: inherit;">Hao Li*â€ </a>,
                </span>
                <span class="author-block">
                  <a href="https://github.com/CiaoHe" style="text-decoration: none; color: inherit;">He Cao*â€ </a>,
                </span>
                <span class="author-block">Bin Feng,</span>
                <span class="author-block">Yanjun Shao,</span>
                <span class="author-block">Xiangru Tang,</span>
                <span class="author-block">Zhiyuan Yan,</span>
                <span class="author-block">Li Yuanâ€ ,</span>
                <span class="author-block">Yonghong Tianâ€ ,</span>
                <span class="author-block">Yu Liâ€ </span>
              </div>

              <br>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><b>Peking University, International Digital Economy Academy (IDEA), Yale University</b></span>
              </div>

              <br>
              <div class="is-size-5 publication-authors">
                <span class="author-block">*Core Contributors</span><br>
                <span class="author-block">â€ Corresponding to:</span>
                <span class="author-block"><a href="mailto:xiangyue.work@gmail.com">lihao1984@pku.edu.cn</a>,</span>
                <span class="author-block"><a href="mailto:su.809@osu.edu">caohe@idea.edu.cn</a>,</span>
                <span class="author-block"><a href="mailto:su.809@osu.edu">yuanli-ece@pku.edu.cn</a>,</span>
                <span class="author-block"><a href="mailto:wenhuchen@uwaterloo.ca">liyu@idea.edu.cn</a></span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2505.21318" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/OpenMol/ChemCoTBench" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="font-size:18px">ðŸ¤—</span>
                      <span>ChemCoTBench</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://huggingface.co/datasets/OpenMol/ChemCoTBench-CoT" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon" style="font-size:18px">ðŸ¤—</span>
                      <span>ChemCoTDataset</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://github.com/HowardLi1984/ChemCoTBench" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code and Evaluation</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="#leaderboard" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon has-text-white">
                        <i class="fa-solid fa-trophy"></i>
                      </span>
                      <span>Leaderboard</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://twitter.com/xiangyue96/status/1729698316554801358" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon has-text-white">
                        <i class="fa-brands fa-x-twitter"></i>
                      </span>
                      <span>Twitter</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop has-text-centered">
        <img src="static/images/dataview.png" alt="geometric reasoning">
        <p><b>Sample Overview</b> of the ChemCoTBench and ChemCoT-Dataset, which contains high-quality chain-of-thought samples from two chemical foundation tasks (molecule understanding, molecule editing) and two application tasks (molecule optimization, reaction prediction)
        </p>
      </div>
    </section>

    <section class="section">
      <div class="container" style="margin-bottom: 2vh;">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">ðŸ””News</h2>
            <div class="content has-text-justified">
              <p>
                <b>ðŸš€[2024-01-31]: We establish the ChemCoTBench and evaluate scores for open-source LLMs, commercial LLMs, and Chemical LLMs on the <a href="#leaderboard">Leaderboard</a>!ðŸŒŸ</b>
              </p>
          </div>
            <h2 class="title is-3">Introduction</h2>
            <div class="content has-text-justified">
              <p>
                <b>Overview of the ChemCoTBench and ChemCoT-Dataset.</b> ChemCoTBench presents four key strengths:
                1) <b>Novel Setup:</b> Beyond ChemQA, itâ€™s the first step-wise chemical reasoning benchmark;
                2) <b>Broad Coverage:</b> Includes foundational tasks (molecule understanding, editing) and two critical applications: molecular optimization (for drug design) and reaction equations (for organic synthesis).;
                3) <b>Large Scale:</b> Provides 1,495 samples across 22 subtasks for benchmarking, plus 17K high-quality Chain-of-Thought samples for model training;
                4) <b>High Quality:</b> Curated by 13 chemistry Ph.D.s from Tsinghua and Peking University, with strict prompt constraints to ensure CoT correctness.
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->
    </div>
    </section>

    <!-- DATASET SECTION -->
    <section class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-1 mmmu">
          <img src="static/images/mmmu_icon2.png" alt="Logo" class="mmmu-logo"/>
          <span class="mmmu">ChemCoT-Benchmark</span>
        </h1>
      </div>
    </section>

    <section class="section">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Overview</h2>
            <div class="content has-text-justified">
              <p>
                Despite recent advances in LLM reasoning capabilities, chemistry, a discipline fundamental to areas like drug discovery and materials science, still lacks a benchmark that assesses whether these improvements extend to its complex, domain-specific problem-solving needs. While several benchmarks have been proposed for LLMs in chemistry, they primarily focus on domain-specific question answering, which suffers from several key limitations:
              </p>
              <p>
                <b>1. Lack of Structured, Stepwise Reasoning and Real-World Relevance:</b> Current evaluations often reduce chemistry assessment to factual recall (e.g., naming compounds or reactions), neglecting the need for operational reasoning akin to arithmetic or coding. Unlike mathematical problems, where solutions demand explicit, verifiable steps, chemistry QA tasks fail to simulate how experts decompose challenges. For instance, they don't capture the process of iteratively refining a moleculeâ€™s substructure to optimize properties, considering crucial real-world factors like synthesizability or toxicity, or deducing reaction mechanisms through intermediate transformations. This gap means we're not fully evaluating the analytical depth required in real-world chemistry. Therefore, evaluations must shift from these textbook-like problems to challenges that better reflect practical applications.
              </p>
              <p>
                <b>2. Ambiguous Skill Attribution in Hybrid Evaluations:</b> Existing benchmarks often conflate reasoning, knowledge recall, and numerical computation into single "exam-style" metricsâ€”for instance, asking LLMs to calculate reaction yields while simultaneously recalling reagent properties. 
                This obscures whether strong performance stems from structured reasoning (e.g., analyzing reaction pathways) or memorized facts (e.g., solvent boiling points). 
                Such ambiguity hinders targeted model improvement and misaligns evaluations with downstream tasks like drug discovery, where success depends on modular reasoning (e.g., decoupling molecular design from synthesizability checks) rather than monolithic problem-solving.
              </p>
              <img src="static/images/chemcotbench-intro.png" alt="algebraic reasoning" class="center">
              <br>
              <p>
                To address these limitations, we introduce ChemCoTBench, a <b>step-by-step</b>, <b>application-oriented</b>, and <b>high-quality</b> benchmark for evaluating LLM reasoning in chemical applications. 
                A core innovation of ChemCoTBench is its formulation of complex chemical tasks, specifically targeting molecular modeling and design, into explicit sequences of verifiable modular chemical operations on SMILES structures (e.g., substructure addition, deletion, or substitution). 
                This approach allows for a granular assessment of an LLM's ability to execute and chain together fundamental chemical transformations. The benchmark features progressively challenging tasks, spanning from basic molecular understanding and editing to property-guided structure optimization and complex multi-molecule chemical reactions. 
                High-quality evaluation is ensured through a dual validation process combining LLM judgment with expert review from 13 chemists.
              </p>
            </div>
          </div>
        </div>

        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-2">Pipeline-and-Statistics</h2>
            <div class="carousel results-carousel">
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="static/images/chemcot-distribution.png" alt="algebraic reasoning" width="95%"/>
                  <p> <b>Distribution analysis for ChemCoTBench. (a)</b> The data samples in two application tasks (molecule optimization, 38%, and reaction prediction, 37%) are slightly larger than the foundation tasks (molecule editing and understanding, 25%) for more challenging evaluation. <b>(b).</b> Samples from both molecular understanding and editing tasks achieved exceptionally high accuracy in chemical expert evaluations of chemical entities, including function group names, molecule names, chemical operation names, reaction information, etc. <b>(c).</b> Samples from molecule optimization and reaction prediction also show high accuracy (> 89%) in chemical expert evaluations.</p>
                </div>
              </div>
              <div class="box m-5">
                <div class="content has-text-centered">
                  <img src="static/images/datapipeline.png" alt="arithmetic reasoning" width="90%"/>
                  <p> <b>Data construction pipeline</b> for ChemCoTBench and ChemCoTDataset.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- RESULTS SECTION -->
    <section class="hero is-light is-small">
      <div class="hero-body has-text-centered">
        <h1 class="title is-1 mmmu">Experiment Results</h1>
      </div>
    </section>

    <section class="section">
      <div class="container">
        <!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
        <div class="columns is-centered m-6">
          <div class="column is-full has-text-centered content">
            <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
            <div class="content has-text-justified">
              <p>
                Our evaluation includes three LLM model categories: 
                <b>(1) Reasoning LLMs</b> with explicit step-by-step reasoning, including Deepseek-R1, o1-mini, o3-mini, Gemini-2.5-pro, Claude-3.7-Sonnet-thinking, Qwen-3-thinking, Llama-Nemotron-thinking; 
                <b>(2) General-purpose non-reasoning LLMs</b> without specialized reasoning mechanisms, including GPT-4o, Qwen-2.5/3~\cite{yang2024qwen2}, Llama-3.3, Gemma-2, Phi-4, OLMo2 
                <b>(3) Biomolecular LLMs</b> including BioMedGPT, BioMistral, and Text+Chem T5. This comprehensive comparison evaluates whether reasoning-specific capabilities provide advantages over domain-specific models in challenging chemical reasoning tasks.
              </p>
            </div>
            <br>
            <!-------------------------------------------------------------------- Molecule Understanding and edit -------------------------------------------------------------------->
            <div class="leaderboard-container">
              <div class="table-wrapper">
                <table id="molecule-table">
                  <thead>
                    <tr>
                      <th colspan="3" class="reset-cell" style="text-align: center;">Model Comparison</th>
                      <th class="pro-details-cell" colspan="2">Func-Group</th>
                      <th class="val-details-cell" colspan="2">Scaffold</th>
                      <th class="test-details-cell" colspan="4">Molecule-Edit</th>
                    </tr>
                    <tr>
                      <th class="sortable" data-sort="string">Name</th>
                      <th class="sortable" data-sort="string">Type</th>
                      <th class="sortable" data-sort="date">Version</th>
                      <th class="sortable pro-overall" data-sort="number">FGâ†“</th>
                      <th class="hidden pro-details sortable" data-sort="number">Ringâ†“</th>
                      <th class="sortable val-overall" data-sort="number">Murckoâ†‘</th>
                      <th class="hidden val-details sortable" data-sort="number">Ring-sysâ†‘</th>
                      <th class="sortable test-overall" data-sort="number">Eq.â†‘</th>
                      <th class="hidden test-details sortable" data-sort="number">Add</th>
                      <th class="hidden test-details sortable" data-sort="number">Delete</th>
                      <th class="hidden test-details sortable" data-sort="number">Sub</th>
                    </tr>
                  </thead>
                  <tbody>
                    <!-- W/ Thinking Section -->
                    <tr class="section-header">
                      <td colspan="11">W/ Thinking</td>
                    </tr>
                    <tr>
                      <td>Gemini-2.5-pro</td>
                      <td>think</td>
                      <td>2.5</td>
                      <td><b>0.11</b></td>
                      <td><b>0.60</b></td>
                      <td><b>0.51</b></td>
                      <td><b>87.5</b></td>
                      <td>82</td>
                      <td><b>100</b></td>
                      <td><b>85</b></td>
                      <td>81.7</td>
                    </tr>
                    <tr>
                      <td>Claude3.7-sonnet</td>
                      <td>think</td>
                      <td>3.7</td>
                      <td>0.21</td>
                      <td>1.60</td>
                      <td>0.40</td>
                      <td>80.0</td>
                      <td><b>84</b></td>
                      <td>85</td>
                      <td>80</td>
                      <td><b>83.4</b></td>
                    </tr>
                    <tr>
                      <td>DeepSeek-R1</td>
                      <td>think</td>
                      <td>R1</td>
                      <td>0.27</td>
                      <td>1.55</td>
                      <td>0.34</td>
                      <td>45.0</td>
                      <td>65</td>
                      <td>70</td>
                      <td>70</td>
                      <td>68.3</td>
                    </tr>
                    <tr>
                      <td>o3-mini</td>
                      <td>think</td>
                      <td>20250103</td>
                      <td>0.13</td>
                      <td><b>0.60</b></td>
                      <td>0.39</td>
                      <td>75.0</td>
                      <td>78</td>
                      <td>65</td>
                      <td>55</td>
                      <td>80.0</td>
                    </tr>
                    <tr>
                      <td>o1-mini</td>
                      <td>think</td>
                      <td>20240912</td>
                      <td>0.21</td>
                      <td>1.25</td>
                      <td>0.25</td>
                      <td>61.7</td>
                      <td>66</td>
                      <td>55</td>
                      <td>80</td>
                      <td>58.3</td>
                    </tr>
                    <tr>
                      <td>Qwen3-235B-A22B</td>
                      <td>think</td>
                      <td>3-235B</td>
                      <td>0.42</td>
                      <td>1.00</td>
                      <td>0.38</td>
                      <td>82.5</td>
                      <td>72</td>
                      <td>40</td>
                      <td>75</td>
                      <td>71.7</td>
                    </tr>
                    <tr>
                      <td>Qwen3-32B</td>
                      <td>think</td>
                      <td>3-32B</td>
                      <td>0.25</td>
                      <td>0.95</td>
                      <td>0.21</td>
                      <td>75.0</td>
                      <td>68</td>
                      <td>20</td>
                      <td>55</td>
                      <td>20.0</td>
                    </tr>
                    <tr>
                      <td>Llama-Nemo-49B</td>
                      <td>think</td>
                      <td>49B</td>
                      <td>0.80</td>
                      <td>1.90</td>
                      <td>0.09</td>
                      <td>86.8</td>
                      <td>46</td>
                      <td>0</td>
                      <td>80</td>
                      <td>8.0</td>
                    </tr>
            
                    <!-- W/o Thinking Section -->
                    <tr class="section-header">
                      <td colspan="11">W/o Thinking</td>
                    </tr>
                    <tr>
                      <td>GPT-4o</td>
                      <td>base</td>
                      <td>20241120</td>
                      <td>0.17</td>
                      <td>1.35</td>
                      <td>0.21</td>
                      <td>80.0</td>
                      <td>72</td>
                      <td>80</td>
                      <td>80</td>
                      <td>65.0</td>
                    </tr>
                    <tr>
                      <td>Deepseek-V3</td>
                      <td>base</td>
                      <td>V3</td>
                      <td>0.15</td>
                      <td>1.50</td>
                      <td>0.24</td>
                      <td>76.7</td>
                      <td>77</td>
                      <td>70</td>
                      <td>75</td>
                      <td>76.7</td>
                    </tr>
                    <tr>
                      <td>Gemini-2.0-flash</td>
                      <td>base</td>
                      <td>2.0</td>
                      <td>0.19</td>
                      <td>1.65</td>
                      <td>0.43</td>
                      <td>75.0</td>
                      <td>76</td>
                      <td>65</td>
                      <td>75</td>
                      <td>66.7</td>
                    </tr>
                    <tr>
                      <td>Qwen3-235B-A22B</td>
                      <td>base</td>
                      <td>3-235B</td>
                      <td>0.42</td>
                      <td>1.00</td>
                      <td>0.34</td>
                      <td>82.5</td>
                      <td>75</td>
                      <td>40</td>
                      <td>75</td>
                      <td>66.7</td>
                    </tr>
                    <tr>
                      <td>Qwen3-32B</td>
                      <td>base</td>
                      <td>3-32B</td>
                      <td>0.26</td>
                      <td>0.95</td>
                      <td>0.22</td>
                      <td>68.3</td>
                      <td>67</td>
                      <td>30</td>
                      <td>55</td>
                      <td>25.0</td>
                    </tr>
                    <tr>
                      <td>Qwen2.5-72B-Instruct</td>
                      <td>base</td>
                      <td>2.5-72B</td>
                      <td>0.26</td>
                      <td><b>0.60</b></td>
                      <td>0.24</td>
                      <td>70.0</td>
                      <td>61</td>
                      <td>70</td>
                      <td>80</td>
                      <td>56.7</td>
                    </tr>
                    <tr>
                      <td>Qwen2.5-32B-Instruct</td>
                      <td>base</td>
                      <td>2.5-32B</td>
                      <td>0.36</td>
                      <td>0.65</td>
                      <td>0.12</td>
                      <td>53.3</td>
                      <td>62</td>
                      <td>50</td>
                      <td>50</td>
                      <td>48.3</td>
                    </tr>
                    <tr>
                      <td>Llama-3.1-70B-Instruct</td>
                      <td>base</td>
                      <td>3.1-70B</td>
                      <td>0.52</td>
                      <td>1.80</td>
                      <td>0.12</td>
                      <td>68.3</td>
                      <td>67</td>
                      <td>60</td>
                      <td>80</td>
                      <td>50.0</td>
                    </tr>
                    <tr>
                      <td>Llama-Nemo-49B</td>
                      <td>base</td>
                      <td>49B</td>
                      <td>0.72</td>
                      <td>1.77</td>
                      <td>0.11</td>
                      <td>65.0</td>
                      <td>54</td>
                      <td>30</td>
                      <td>55</td>
                      <td>30.5</td>
                    </tr>
                    <tr>
                      <td>Gemma-2-27b-it</td>
                      <td>base</td>
                      <td>2-27b</td>
                      <td>0.19</td>
                      <td>1.65</td>
                      <td>0.43</td>
                      <td>66.7</td>
                      <td>76</td>
                      <td>75</td>
                      <td>70</td>
                      <td>35.0</td>
                    </tr>
                    <tr>
                      <td>Phi-4-14B</td>
                      <td>base</td>
                      <td>4-14B</td>
                      <td>0.28</td>
                      <td>1.65</td>
                      <td>0.15</td>
                      <td>70.0</td>
                      <td>65</td>
                      <td>60</td>
                      <td>80</td>
                      <td>38.3</td>
                    </tr>
                    <tr>
                      <td>OLMo2-32B-Instruct</td>
                      <td>base</td>
                      <td>2-32B</td>
                      <td>0.19</td>
                      <td>1.05</td>
                      <td>0.07</td>
                      <td>63.3</td>
                      <td>50</td>
                      <td>15</td>
                      <td>30</td>
                      <td>11.7</td>
                    </tr>
                    <tr>
                      <td>BioMedGPT-7B</td>
                      <td>base</td>
                      <td>7B</td>
                      <td>1.6</td>
                      <td>2.43</td>
                      <td>0.18</td>
                      <td>53.3</td>
                      <td>39</td>
                      <td>10</td>
                      <td>12</td>
                      <td>10</td>
                    </tr>
                    <tr>
                      <td>BioMistral-7B</td>
                      <td>base</td>
                      <td>7B</td>
                      <td>1.0</td>
                      <td>1.85</td>
                      <td>0.04</td>
                      <td>32.5</td>
                      <td>50</td>
                      <td>0</td>
                      <td>10</td>
                      <td>0</td>
                    </tr>
                  </tbody>
                </table>
                <p class="test-desc">Overall results of different models on molecular tasks. The best-performing model in each category is <b>in-bold</b>. â†“ indicates lower is better, â†‘ indicates higher is better.</p>
              </div>
            </div>
            <!-------------------------------------------------------------------- Molecule Optimization -------------------------------------------------------------------->
            <div class="model-labels-container">
              <span class="leaderboard-label human_expert">Reasoning-LLM</span>
              <span class="leaderboard-label open_source">None-Reasoning-LLM</span>
              <span class="leaderboard-label proprietary">Chemical-LLM</span>
            </div>
            <br>
            <div class="content has-text-centered">
              <p>
                Molecule Optimization Evaluation.
              </p>
            </div>
            <div class="leaderboard-container">
              <div class="table-wrapper">
                <table id="chemistry-table">
                  <thead>
                    <tr>
                      <th rowspan="2" class="sortable clickable" data-sort="string">Models</th>
                      <th colspan="2" class="clickable">LogP</th>
                      <th colspan="2" class="clickable">Solubility</th>
                      <th colspan="2" class="clickable">QED</th>
                      <th colspan="2" class="clickable">DRD2</th>
                      <th colspan="2" class="clickable">JNK3</th>
                      <th colspan="2" class="clickable">GSK3-Î²</th>
                    </tr>
                    <tr>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                      <th class="sortable clickable" data-sort="number">Î”</th>
                      <th class="sortable clickable" data-sort="number">SR%</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr class="group-header">
                      <td colspan="13"><em>W/ Thinking</em></td>
                    </tr>
                    <tr>
                      <td>Gemini-2.5-pro-think</td>
                      <td>-0.28</td><td><b>81</b></td>
                      <td>1.91</td><td>92</td>
                      <td><b>0.21</b></td><td>84</td>
                      <td><b>0.35</b></td><td><b>74</b></td>
                      <td>-0.04</td><td>35</td>
                      <td><b>0.04</b></td><td><b>68</b></td>
                    </tr>
                    <tr>
                      <td>Claude3.7-sonnet-think</td>
                      <td><b>0.41</b></td><td><b>81</b></td>
                      <td>0.59</td><td>77</td>
                      <td>0.09</td><td>73</td>
                      <td>0.18</td><td>66</td>
                      <td>-0.01</td><td><b>49</b></td>
                      <td>0.01</td><td>57</td>
                    </tr>
                    <tr>
                      <td>DeepSeek-R1</td>
                      <td>0.36</td><td>74</td>
                      <td>1.48</td><td><b>97</b></td>
                      <td>0.05</td><td>72</td>
                      <td>0.10</td><td>62</td>
                      <td>-0.06</td><td>29</td>
                      <td>-0.02</td><td>41</td>
                    </tr>
                    <tr>
                      <td>o3-mini@20250103</td>
                      <td>0.29</td><td>68</td>
                      <td>1.15</td><td>85</td>
                      <td>0.17</td><td><b>86</b></td>
                      <td>0.18</td><td>69</td>
                      <td>-0.08</td><td>23</td>
                      <td>-0.03</td><td>45</td>
                    </tr>
                    <tr>
                      <td>o1-mini@20240912</td>
                      <td>-0.42</td><td>52</td>
                      <td>1.78</td><td>95</td>
                      <td>0.07</td><td>70</td>
                      <td>-0.03</td><td>37</td>
                      <td>-0.10</td><td>15</td>
                      <td>-0.08</td><td>31</td>
                    </tr>
                    <tr>
                      <td>Qwen3-235B-A22B-think</td>
                      <td>-0.01</td><td>41</td>
                      <td>0.27</td><td>42</td>
                      <td>0.01</td><td>24</td>
                      <td>0.03</td><td>31</td>
                      <td>-0.01</td><td>23</td>
                      <td>0.01</td><td>31</td>
                    </tr>
                    <tr>
                      <td>Qwen3-32B-think</td>
                      <td>0.0</td><td>2</td>
                      <td>0.11</td><td>23</td>
                      <td>0.02</td><td>14</td>
                      <td>0.0</td><td>6</td>
                      <td>-0.02</td><td>6</td>
                      <td>-0.02</td><td>5</td>
                    </tr>
                    <tr>
                      <td>Llama-Nemo-49B-think</td>
                      <td>-0.64</td><td>24</td>
                      <td>0.20</td><td>24</td>
                      <td>-0.16</td><td>41</td>
                      <td>-0.05</td><td>30</td>
                      <td>-0.15</td><td>7</td>
                      <td>-0.12</td><td>11</td>
                    </tr>
            
                    <tr class="group-header">
                      <td colspan="13"><em>W/o Thinking</em></td>
                    </tr>
                    <tr>
                      <td>GPT-4o@20241120</td>
                      <td>-0.20</td><td>42</td>
                      <td>0.82</td><td>80</td>
                      <td>0.05</td><td>70</td>
                      <td>0.05</td><td>48</td>
                      <td>-0.05</td><td>30</td>
                      <td>-0.04</td><td>39</td>
                    </tr>
                    <tr>
                      <td>DeepSeek-V3</td>
                      <td>0.08</td><td>34</td>
                      <td>0.47</td><td>93</td>
                      <td>0.08</td><td>46</td>
                      <td>0.02</td><td>28</td>
                      <td>0.0</td><td>18</td>
                      <td>0.0</td><td>29</td>
                    </tr>
                    <tr>
                      <td>Gemini-2.0-flash</td>
                      <td>0.35</td><td>75</td>
                      <td>0.19</td><td>54</td>
                      <td>0.10</td><td>79</td>
                      <td>0.15</td><td>63</td>
                      <td><b>0.03</b></td><td>34</td>
                      <td>0.0</td><td>38</td>
                    </tr>
                    <tr>
                      <td>Qwen3-235B-A22B</td>
                      <td>0.02</td><td>41</td>
                      <td>0.51</td><td>45</td>
                      <td>0.01</td><td>26</td>
                      <td>0.01</td><td>31</td>
                      <td>-0.01</td><td>23</td>
                      <td>0.0</td><td>34</td>
                    </tr>
                    <tr>
                      <td>Qwen3-32B</td>
                      <td>-0.03</td><td>2</td>
                      <td>0.17</td><td>23</td>
                      <td>0.02</td><td>14</td>
                      <td>-0.01</td><td>6</td>
                      <td>-0.02</td><td>6</td>
                      <td>-0.02</td><td>5</td>
                    </tr>
                    <tr>
                      <td>Qwen2.5-72B-Instruct</td>
                      <td>-0.12</td><td>42</td>
                      <td>0.28</td><td>60</td>
                      <td>0.03</td><td>57</td>
                      <td>0.04</td><td>40</td>
                      <td>-0.02</td><td>26</td>
                      <td>-0.01</td><td>40</td>
                    </tr>
                    <tr>
                      <td>Qwen2.5-32B-Instruct</td>
                      <td>0.03</td><td>47</td>
                      <td>0.42</td><td>66</td>
                      <td>-0.01</td><td>54</td>
                      <td>0.04</td><td>32</td>
                      <td>-0.04</td><td>19</td>
                      <td>-0.02</td><td>31</td>
                    </tr>
                    <tr>
                      <td>Llama-3.3-70B-Instruct</td>
                      <td>-0.16</td><td>42</td>
                      <td>0.61</td><td>80</td>
                      <td>0.07</td><td>61</td>
                      <td>-0.02</td><td>31</td>
                      <td>-0.04</td><td>30</td>
                      <td>-0.02</td><td>40</td>
                    </tr>
                    <tr>
                      <td>Llama-Nemo-Super-49B</td>
                      <td>-0.14</td><td>27</td>
                      <td>0.31</td><td>41</td>
                      <td>0.02</td><td>50</td>
                      <td>-0.02</td><td>18</td>
                      <td>-0.04</td><td>16</td>
                      <td>-0.03</td><td>27</td>
                    </tr>
                    <tr>
                      <td>Gemma-2-27b-it</td>
                      <td>-0.03</td><td>34</td>
                      <td>0.34</td><td>66</td>
                      <td>0.05</td><td>56</td>
                      <td>-0.03</td><td>15</td>
                      <td>0.0</td><td>16</td>
                      <td>-0.01</td><td>17</td>
                    </tr>
                    <tr>
                      <td>Phi-4-14B</td>
                      <td>-0.10</td><td>45</td>
                      <td>0.28</td><td>54</td>
                      <td>0.11</td><td>74</td>
                      <td>-0.04</td><td>18</td>
                      <td>-0.05</td><td>14</td>
                      <td>-0.04</td><td>22</td>
                    </tr>
                    <tr>
                      <td>OLMo2-32B-Instruct</td>
                      <td>-2.03</td><td>22</td>
                      <td>1.03</td><td>46</td>
                      <td>-0.13</td><td>40</td>
                      <td>-0.11</td><td>7</td>
                      <td>-0.12</td><td>8</td>
                      <td>-0.11</td><td>12</td>
                    </tr>
                  </tbody>
                </table>
                <p class="test-desc">Results of different models on chemistry benchmarks. The best-performing model in each category is <b>in-bold</b>.</p>
              </div>
            </div>
          </div>
        </div>
      <!-------------------------------------------------------------------- Chemical Reaction -------------------------------------------------------------------->
        <div class="leaderboard-container">
          <div class="table-wrapper">
            <table id="mmmu-table">
              <thead>
                <tr>
                  <th colspan="1" class="reset-cell clickable" style="text-align: center;">Reset</th>
                  <th class="pro-details-cell clickable" colspan="2">Fwd subscript major</th>
                  <th class="val-details-cell clickable" colspan="2">Fwd subcript by</th>
                  <th class="test-details-cell clickable" colspan="2">Retro</th>
                  <th class="test-details-cell clickable" colspan="2">Condition</th>
                  <th class="test-details-cell clickable" colspan="2">NEPP</th>
                  <th class="test-details-cell clickable" colspan="1">MechSel</th>
                </tr>
                <tr>
                  <th class="sortable clickable" data-sort="string">Models</th>
                  <th class="sortable clickable" data-sort="number">Top-1</th>
                  <th class="sortable clickable" data-sort="number">FTS$\uparrow$</th>
                  <th class="sortable clickable" data-sort="number">Top-1</th>
                  <th class="sortable clickable" data-sort="number">FTS$\uparrow$</th>
                  <th class="sortable clickable" data-sort="number">Top-1</th>
                  <th class="sortable clickable" data-sort="number">FTS$\uparrow$</th>
                  <th class="sortable clickable" data-sort="number">Top-1</th>
                  <th class="sortable clickable" data-sort="number">FTS$\uparrow$</th>
                  <th class="sortable clickable" data-sort="number">Top-1</th>
                  <th class="sortable clickable" data-sort="number">FTS$\uparrow$</th>
                  <th class="sortable clickable" data-sort="number">Acc.$\uparrow$</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td colspan="12" style="text-align: center; font-style: italic; border-top: 2px dashed #ccc;">W/ Thinking</td>
                </tr>
                <tr>
                  <td>Gemini-2.5-pro-think</td>
                  <td>0.72</td>
                  <td><b>0.89</b></td>
                  <td>0.20</td>
                  <td><b>0.51</b></td>
                  <td><b>0.20</b></td>
                  <td><b>0.45</b></td>
                  <td>0.20</td>
                  <td><b>0.33</b></td>
                  <td><b>0.58</b></td>
                  <td>0.53</td>
                  <td><b>0.62</b></td>
                </tr>
                <tr>
                  <td>Claude3.7-sonnet-think</td>
                  <td><b>0.73</b></td>
                  <td>0.87</td>
                  <td><b>0.25</b></td>
                  <td>0.31</td>
                  <td>0.12</td>
                  <td>0.27</td>
                  <td>0.14</td>
                  <td>0.22</td>
                  <td>0.24</td>
                  <td><b>0.79</b></td>
                  <td>0.49</td>
                </tr>
                <tr>
                  <td>DeepSeek-R1</td>
                  <td>0.48</td>
                  <td>0.71</td>
                  <td>0.21</td>
                  <td>0.45</td>
                  <td>0.07</td>
                  <td>0.41</td>
                  <td><b>0.23</b></td>
                  <td>0.30</td>
                  <td>0.15</td>
                  <td>0.55</td>
                  <td>0.46</td>
                </tr>
                <tr>
                  <td>o3-mini@20250103</td>
                  <td>0.52</td>
                  <td>0.71</td>
                  <td>0.20</td>
                  <td>0.27</td>
                  <td>0.11</td>
                  <td>0.39</td>
                  <td>0.19</td>
                  <td>0.19</td>
                  <td>0.18</td>
                  <td>0.58</td>
                  <td>0.49</td>
                </tr>
                <tr>
                  <td>o1-mini@20240912</td>
                  <td>0.26</td>
                  <td>0.31</td>
                  <td>0.11</td>
                  <td>0.17</td>
                  <td>0.02</td>
                  <td>0.15</td>
                  <td>0.08</td>
                  <td>0.22</td>
                  <td>0.09</td>
                  <td>0.33</td>
                  <td>0.44</td>
                </tr>
                <tr>
                  <td>Qwen3-235B-A22B-think</td>
                  <td>0.03</td>
                  <td>0.54</td>
                  <td>0.0</td>
                  <td>0.07</td>
                  <td>0.01</td>
                  <td>0.42</td>
                  <td>0.20</td>
                  <td>0.27</td>
                  <td>0.09</td>
                  <td>0.63</td>
                  <td>0.41</td>
                </tr>
                <tr>
                  <td>Qwen3-32B-think</td>
                  <td>0.11</td>
                  <td>0.33</td>
                  <td>0.09</td>
                  <td>0.18</td>
                  <td>0.02</td>
                  <td>0.24</td>
                  <td>0.14</td>
                  <td>0.20</td>
                  <td>0.08</td>
                  <td>0.67</td>
                  <td>0.46</td>
                </tr>
                <tr>
                  <td>Llama-Nemo-49B-think</td>
                  <td>0.09</td>
                  <td>0.18</td>
                  <td>0.04</td>
                  <td>0.18</td>
                  <td>0.0</td>
                  <td>0.05</td>
                  <td>0.18</td>
                  <td>0.19</td>
                  <td>0.04</td>
                  <td>0.21</td>
                  <td>0.47</td>
                </tr>
                <tr>
                  <td colspan="12" style="text-align: center; font-style: italic; border-top: 2px dashed #ccc;">W/o Thinking</td>
                </tr>
                <tr>
                  <td>GPT-4o@20241120</td>
                  <td>0.28</td>
                  <td>0.58</td>
                  <td>0.04</td>
                  <td>0.20</td>
                  <td>0.03</td>
                  <td>0.43</td>
                  <td>0.0</td>
                  <td>0.08</td>
                  <td>0.12</td>
                  <td>0.71</td>
                  <td>0.43</td>
                </tr>
                <tr>
                  <td>DeepSeek-V3</td>
                  <td>0.36</td>
                  <td>0.62</td>
                  <td>0.04</td>
                  <td>0.30</td>
                  <td>0.03</td>
                  <td>0.44</td>
                  <td>0.08</td>
                  <td>0.16</td>
                  <td>0.20</td>
                  <td>0.70</td>
                  <td>0.45</td>
                </tr>
                <tr>
                  <td>Gemini-2.0-flash</td>
                  <td>0.19</td>
                  <td>0.56</td>
                  <td>0.01</td>
                  <td>0.07</td>
                  <td>0.05</td>
                  <td>0.41</td>
                  <td>0.07</td>
                  <td>0.08</td>
                  <td>0.13</td>
                  <td>0.68</td>
                  <td>0.53</td>
                </tr>
                <tr>
                  <td>Qwen3-235B-A22B</td>
                  <td>0.04</td>
                  <td>0.57</td>
                  <td>0.0</td>
                  <td>0.06</td>
                  <td>0.0</td>
                  <td>0.30</td>
                  <td>0.07</td>
                  <td>0.14</td>
                  <td>0.07</td>
                  <td>0.59</td>
                  <td>0.40</td>
                </tr>
                <tr>
                  <td>Qwen3-32B</td>
                  <td>0.06</td>
                  <td>0.57</td>
                  <td>0.0</td>
                  <td>0.13</td>
                  <td>0.0</td>
                  <td>0.43</td>
                  <td>0.01</td>
                  <td>0.10</td>
                  <td>0.08</td>
                  <td>0.67</td>
                  <td>0.46</td>
                </tr>
                <tr>
                  <td>Qwen2.5-72B-Instruct</td>
                  <td>0.04</td>
                  <td>0.49</td>
                  <td>0.0</td>
                  <td>0.13</td>
                  <td>0.01</td>
                  <td>0.35</td>
                  <td>0.01</td>
                  <td>0.07</td>
                  <td>0.06</td>
                  <td>0.60</td>
                  <td>0.46</td>
                </tr>
                <tr>
                  <td>Qwen2.5-32B-Instruct</td>
                  <td>0.01</td>
                  <td>0.43</td>
                  <td>0.0</td>
                  <td>0.12</td>
                  <td>0.0</td>
                  <td>0.29</td>
                  <td>0.02</td>
                  <td>0.10</td>
                  <td>0.05</td>
                  <td>0.50</td>
                  <td>0.45</td>
                </tr>
                <tr>
                  <td>Llama-3.3-70B-Instruct</td>
                  <td>0.02</td>
                  <td>0.35</td>
                  <td>0.0</td>
                  <td>0.08</td>
                  <td>0.0</td>
                  <td>0.34</td>
                  <td>0.06</td>
                  <td>0.13</td>
                  <td>0.06</td>
                  <td>0.41</td>
                  <td>0.39</td>
                </tr>
                <tr>
                  <td>Llama-Nemo-49B</td>
                  <td>0.04</td>
                  <td>0.40</td>
                  <td>0.0</td>
                  <td>0.08</td>
                  <td>0.0</td>
                  <td>0.30</td>
                  <td>0.03</td>
                  <td>0.05</td>
                  <td>0.05</td>
                  <td>0.41</td>
                  <td>0.46</td>
                </tr>
                <tr>
                  <td>Gemma-2-27b-it</td>
                  <td>0.01</td>
                  <td>0.55</td>
                  <td>0.0</td>
                  <td>0.04</td>
                  <td>0.0</td>
                  <td>0.48</td>
                  <td>0.03</td>
                  <td>0.10</td>
                  <td>0.04</td>
                  <td>0.53</td>
                  <td>0.43</td>
                </tr>
                <tr>
                  <td>Phi-4-14B</td>
                  <td>0.01</td>
                  <td>0.27</td>
                  <td>0.03</td>
                  <td>0.10</td>
                  <td>0.0</td>
                  <td>0.39</td>
                  <td>0.0</td>
                  <td>0.03</td>
                  <td>0.05</td>
                  <td>0.57</td>
                  <td>0.39</td>
                </tr>
                <tr>
                  <td>OLMo2-32B-Instruct</td>
                  <td>0.0</td>
                  <td>0.10</td>
                  <td>0.0</td>
                  <td>0.07</td>
                  <td>0.0</td>
                  <td>0.10</td>
                  <td>0.0</td>
                  <td>0.03</td>
                  <td>0.01</td>
                  <td>0.13</td>
                  <td>0.32</td>
                </tr>
                <tr>
                  <td>Text+Chem T5</td>
                  <td>0.44</td>
                  <td>0.74</td>
                  <td>0.0</td>
                  <td>0.07</td>
                  <td>0.06</td>
                  <td>0.24</td>
                  <td>0.0</td>
                  <td>0.09</td>
                  <td>0.0</td>
                  <td>0.0</td>
                  <td>0.10</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </section>

    <!-- @PAN TODO: bibtex -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title is-3 has-text-centered">BibTeX</h2>
        <pre><code>
          @inproceedings{yue2023mmmu,
            title={MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI},
            author={Xiang Yue and Yuansheng Ni and Kai Zhang and Tianyu Zheng and Ruoqi Liu and Ge Zhang and Samuel Stevens and Dongfu Jiang and Weiming Ren and Yuxuan Sun and Cong Wei and Botao Yu and Ruibin Yuan and Renliang Sun and Ming Yin and Boyuan Zheng and Zhenzhu Yang and Yibo Liu and Wenhao Huang and Huan Sun and Yu Su and Wenhu Chen},
            booktitle={Proceedings of CVPR},
            year={2024},
          }
    </code></pre>
      </div>
    </section>

    <footer class="footer">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is website adapted from <a href="https://nerfies.github.io/">Nerfies</a> and <a href="https://mathvista.github.io/">MathVista</a>, licensed under a <a rel="license"
                                                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </footer>

  </body>
</html>
